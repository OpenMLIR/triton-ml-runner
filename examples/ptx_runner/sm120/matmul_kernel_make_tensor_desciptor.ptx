//
// Generated by LLVM NVPTX Back-End
//

.version 8.7
.target sm_120a
.address_size 64

	// .globl	matmul_kernel_make_tensor_desciptor // -- Begin function matmul_kernel_make_tensor_desciptor
.extern .shared .align 16 .b8 global_smem[];
                                        // @matmul_kernel_make_tensor_desciptor
.visible .entry matmul_kernel_make_tensor_desciptor(
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_0,
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_1,
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_2,
	.param .u32 matmul_kernel_make_tensor_desciptor_param_3,
	.param .u32 matmul_kernel_make_tensor_desciptor_param_4,
	.param .u32 matmul_kernel_make_tensor_desciptor_param_5,
	.param .u64 .ptr .global .align 1 matmul_kernel_make_tensor_desciptor_param_6
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<88>;
	.reg .b16 	%rs<193>;
	.reg .b32 	%r<1130>;
	.reg .f32 	%f<706>;
	.reg .b64 	%rd<69>;
	.loc	1 9 0                           // matmul-with-tma-v3.py:9:0
$L__func_begin0:
	.loc	1 9 0                           // matmul-with-tma-v3.py:9:0

// %bb.0:
	ld.param.u64 	%rd5, [matmul_kernel_make_tensor_desciptor_param_0];
	ld.param.u64 	%rd23, [matmul_kernel_make_tensor_desciptor_param_1];
$L__tmp0:
	.loc	1 14 26                         // matmul-with-tma-v3.py:14:26
	mov.u32 	%r194, %ctaid.x;
	ld.param.u64 	%rd41, [matmul_kernel_make_tensor_desciptor_param_2];
	.loc	1 15 26                         // matmul-with-tma-v3.py:15:26
	mov.u32 	%r195, %ctaid.y;
	ld.param.u32 	%r154, [matmul_kernel_make_tensor_desciptor_param_4];
	.loc	1 18 8                          // matmul-with-tma-v3.py:18:8
	cvt.s64.s32 	%rd12, %r154;
	ld.param.u32 	%r155, [matmul_kernel_make_tensor_desciptor_param_3];
	mov.u32 	%r196, %ctaid.z;
	ld.param.u32 	%r162, [matmul_kernel_make_tensor_desciptor_param_5];
	mov.u32 	%r197, %nctaid.x;
	ld.param.u64 	%rd62, [matmul_kernel_make_tensor_desciptor_param_6];
	mov.u32 	%r198, %nctaid.y;
	mad.lo.s32 	%r199, %r196, %r198, %r195;
	mad.lo.s32 	%r200, %r199, %r197, %r194;
	mul.lo.s32 	%r201, %r200, 384;
	cvt.s64.s32 	%rd63, %r201;
	add.s64 	%rd60, %rd62, %rd63;
	mov.u32 	%r1, %tid.x;
	setp.lt.s32 	%p1, %r1, 32;
	shl.b32 	%r202, %r1, 2;
	mov.u32 	%r177, global_smem;
	add.s32 	%r150, %r177, %r202;
	mov.b32 	%r1098, 0;
	// begin inline asm
	@%p1 st.shared.b32 [ %r150 + 0 ], %r1098;
	// end inline asm
	bar.warp.sync 	-1;
	setp.eq.s32 	%p81, %r1, 0;
	cvt.u64.u32 	%rd4, %r177;
	// begin inline asm
	@%p81 tensormap.replace.tile.global_address.shared::cta.b1024.b64 [ %rd4 + 0 ], %rd5;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.rank.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1;
	// end inline asm
	mov.b32 	%r152, 64;
	// begin inline asm
	@%p81 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r152;
	// end inline asm
	mov.b32 	%r1089, 128;
	// begin inline asm
	@%p81 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r1089;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r154;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r155;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [ %rd4 + 0 ], 0x0, %rd12;
	// end inline asm
	mov.b32 	%r1092, 1;
	// begin inline asm
	@%p81 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r1092;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r1092;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.elemtype.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.interleave_layout.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.swizzle_mode.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x2;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.fill_mode.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p1 tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [ %rd60 + 0 ], [ %rd4 + 0 ], 0x80;
	// end inline asm
	// begin inline asm
	@%p1 fence.proxy.tensormap::generic.acquire.gpu [ %rd60 + 0 ], 0x80;
	// end inline asm
	bar.sync 	0;
	.loc	1 24 8                          // matmul-with-tma-v3.py:24:8
	cvt.s64.s32 	%rd30, %r162;
	add.s32 	%r203, %r201, 128;
	cvt.s64.s32 	%rd64, %r203;
	add.s64 	%rd61, %rd62, %rd64;
	bar.sync 	0;
	// begin inline asm
	@%p1 st.shared.b32 [ %r150 + 0 ], %r1098;
	// end inline asm
	bar.warp.sync 	-1;
	// begin inline asm
	@%p81 tensormap.replace.tile.global_address.shared::cta.b1024.b64 [ %rd4 + 0 ], %rd23;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.rank.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r152;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r152;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r162;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r154;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [ %rd4 + 0 ], 0x0, %rd30;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r1092;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r1092;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.elemtype.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.interleave_layout.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.swizzle_mode.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x2;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.fill_mode.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p1 tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [ %rd61 + 0 ], [ %rd4 + 0 ], 0x80;
	// end inline asm
	// begin inline asm
	@%p1 fence.proxy.tensormap::generic.acquire.gpu [ %rd61 + 0 ], 0x80;
	// end inline asm
	bar.sync 	0;
	.loc	1 30 8                          // matmul-with-tma-v3.py:30:8
	add.s32 	%r204, %r201, 256;
	cvt.s64.s32 	%rd65, %r204;
	add.s64 	%rd68, %rd62, %rd65;
	mul.wide.s32 	%rd48, %r162, 2;
	bar.sync 	0;
	// begin inline asm
	@%p1 st.shared.b32 [ %r150 + 0 ], %r1098;
	// end inline asm
	bar.warp.sync 	-1;
	// begin inline asm
	@%p81 tensormap.replace.tile.global_address.shared::cta.b1024.b64 [ %rd4 + 0 ], %rd41;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.rank.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r152;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.box_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r1089;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r162;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_dim.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r155;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.global_stride.shared::cta.b1024.b64 [ %rd4 + 0 ], 0x0, %rd48;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0, %r1092;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.element_stride.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1, %r1092;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.elemtype.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x1;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.interleave_layout.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.swizzle_mode.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x3;
	// end inline asm
	// begin inline asm
	@%p81 tensormap.replace.tile.fill_mode.shared::cta.b1024.b32 [ %rd4 + 0 ], 0x0;
	// end inline asm
	// begin inline asm
	@%p1 tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned [ %rd68 + 0 ], [ %rd4 + 0 ], 0x80;
	// end inline asm
	// begin inline asm
	@%p1 fence.proxy.tensormap::generic.acquire.gpu [ %rd68 + 0 ], 0x80;
	// end inline asm
	bar.sync 	0;
$L__tmp1:
	.loc	2 40 22                         // standard.py:40:22
	add.s32 	%r205, %r154, 63;
$L__tmp2:
	.loc	1 38 33                         // matmul-with-tma-v3.py:38:33
	shl.b32 	%r930, %r194, 7;
	.loc	1 39 51                         // matmul-with-tma-v3.py:39:51
	shl.b32 	%r929, %r195, 6;
	.loc	1 37 19                         // matmul-with-tma-v3.py:37:19
	add.s32 	%r174, %r177, 24576;
	// begin inline asm
	@%p81 mbarrier.init.shared::cta.b64 [%r174], 1;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r175, %r177, 24584;
	// begin inline asm
	@%p81 mbarrier.init.shared::cta.b64 [%r175], 1;
	// end inline asm
	setp.gt.s32 	%p57, %r205, 63;
	bar.sync 	0;
	and.pred  	%p51, %p81, %p57;
	// begin inline asm
	@%p51 mbarrier.arrive.expect_tx.shared.b64 _, [%r174], 12288;
	// end inline asm
	.loc	1 38 24                         // matmul-with-tma-v3.py:38:24
	bar.sync 	0;
	elect.sync 	%r209|%p58, -1;
	and.pred  	%p59, %p57, %p58;
	setp.lt.u32 	%p60, %r1, 32;
	and.pred  	%p52, %p60, %p59;
	// begin inline asm
	@%p52 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r177], [%rd60, {%r1098, %r930}], [%r174];
	// end inline asm
	.loc	1 39 24                         // matmul-with-tma-v3.py:39:24
	bar.sync 	0;
	elect.sync 	%r210|%p61, -1;
	and.pred  	%p62, %p57, %p61;
	and.pred  	%p53, %p60, %p62;
	add.s32 	%r181, %r177, 16384;
	// begin inline asm
	@%p53 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r181], [%rd61, {%r929, %r1098}], [%r174];
	// end inline asm
	.loc	1 37 19                         // matmul-with-tma-v3.py:37:19
	setp.gt.s32 	%p63, %r205, 127;
	bar.sync 	0;
	and.pred  	%p54, %p81, %p63;
	// begin inline asm
	@%p54 mbarrier.arrive.expect_tx.shared.b64 _, [%r175], 12288;
	// end inline asm
	.loc	1 38 24                         // matmul-with-tma-v3.py:38:24
	bar.sync 	0;
	elect.sync 	%r211|%p64, -1;
	and.pred  	%p65, %p63, %p64;
	and.pred  	%p55, %p60, %p65;
	add.s32 	%r186, %r177, 8192;
	// begin inline asm
	@%p55 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r186], [%rd60, {%r152, %r930}], [%r175];
	// end inline asm
	.loc	1 39 24                         // matmul-with-tma-v3.py:39:24
	bar.sync 	0;
	elect.sync 	%r212|%p66, -1;
	and.pred  	%p67, %p63, %p66;
	and.pred  	%p56, %p60, %p67;
	add.s32 	%r190, %r177, 20480;
	// begin inline asm
	@%p56 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r190], [%rd61, {%r929, %r152}], [%r175];
	// end inline asm
	.loc	1 37 19                         // matmul-with-tma-v3.py:37:19
	@%p57 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:                              // %.lr.ph
	.loc	1 0 19                          // matmul-with-tma-v3.py:0:19
	shr.s32 	%r206, %r205, 31;
	shr.u32 	%r207, %r206, 26;
	add.s32 	%r208, %r205, %r207;
	shr.s32 	%r2, %r208, 6;
	add.s32 	%r9, %r2, -2;
	and.b32  	%r251, %r1, 1;
	neg.s32 	%r252, %r251;
	and.b32  	%r253, %r252, 288;
	shl.b32 	%r254, %r1, 8;
	and.b32  	%r255, %r254, 512;
	and.b32  	%r1097, %r1, 8;
	bfe.s32 	%r256, %r1, 3, 1;
	shr.u32 	%r257, %r1, 2;
	bfe.u32 	%r258, %r1, 2, 2;
	bfe.s32 	%r259, %r1, 4, 1;
	and.b32  	%r1096, %r1, 16;
	shr.u32 	%r260, %r1096, 2;
	or.b32  	%r261, %r258, %r255;
	or.b32  	%r262, %r261, %r260;
	or.b32  	%r263, %r262, %r253;
	and.b32  	%r1095, %r257, 8;
	or.b32  	%r13, %r263, %r1095;
	xor.b32  	%r14, %r13, 32;
	xor.b32  	%r15, %r13, 96;
	xor.b32  	%r16, %r13, 176;
	xor.b32  	%r17, %r13, 240;
	xor.b32  	%r18, %r13, 1056;
	xor.b32  	%r19, %r13, 1120;
	xor.b32  	%r20, %r13, 1200;
	xor.b32  	%r21, %r13, 1264;
	xor.b32  	%r22, %r13, 2080;
	xor.b32  	%r23, %r13, 2144;
	xor.b32  	%r24, %r13, 2224;
	xor.b32  	%r25, %r13, 2288;
	xor.b32  	%r26, %r13, 3104;
	xor.b32  	%r27, %r13, 3168;
	xor.b32  	%r28, %r13, 3248;
	xor.b32  	%r29, %r13, 3312;
	xor.b32  	%r30, %r13, 48;
	xor.b32  	%r31, %r13, 112;
	xor.b32  	%r32, %r13, 160;
	xor.b32  	%r33, %r13, 224;
	xor.b32  	%r34, %r13, 1072;
	xor.b32  	%r35, %r13, 1136;
	xor.b32  	%r36, %r13, 1184;
	xor.b32  	%r37, %r13, 1248;
	xor.b32  	%r38, %r13, 2096;
	xor.b32  	%r39, %r13, 2160;
	xor.b32  	%r40, %r13, 2208;
	xor.b32  	%r41, %r13, 2272;
	xor.b32  	%r42, %r13, 3120;
	xor.b32  	%r43, %r13, 3184;
	xor.b32  	%r44, %r13, 3232;
	xor.b32  	%r45, %r13, 3296;
	and.b32  	%r265, %r202, 12;
	shl.b32 	%r266, %r1, 4;
	and.b32  	%r267, %r266, 64;
	or.b32  	%r268, %r265, %r267;
	and.b32  	%r269, %r256, 144;
	or.b32  	%r270, %r268, %r269;
	and.b32  	%r271, %r259, 288;
	and.b32  	%r1094, %r266, 1024;
	or.b32  	%r272, %r271, %r1094;
	or.b32  	%r47, %r272, %r270;
	or.b32  	%r273, %r268, 16;
	xor.b32  	%r274, %r273, %r269;
	or.b32  	%r275, %r1094, %r274;
	or.b32  	%r48, %r275, %r271;
	or.b32  	%r276, %r268, 528;
	xor.b32  	%r277, %r276, %r269;
	or.b32  	%r278, %r1094, %r277;
	or.b32  	%r49, %r278, %r271;
	or.b32  	%r279, %r270, 32;
	xor.b32  	%r280, %r279, %r271;
	or.b32  	%r50, %r280, %r1094;
	or.b32  	%r281, %r270, 544;
	xor.b32  	%r282, %r281, %r271;
	or.b32  	%r51, %r282, %r1094;
	or.b32  	%r283, %r268, 48;
	or.b32  	%r284, %r271, %r269;
	xor.b32  	%r285, %r284, %r283;
	or.b32  	%r52, %r285, %r1094;
	or.b32  	%r286, %r268, 560;
	xor.b32  	%r287, %r284, %r286;
	or.b32  	%r53, %r287, %r1094;
	or.b32  	%r288, %r268, 2064;
	xor.b32  	%r289, %r288, %r269;
	or.b32  	%r290, %r1094, %r289;
	or.b32  	%r54, %r290, %r271;
	or.b32  	%r291, %r268, 2576;
	xor.b32  	%r292, %r291, %r269;
	or.b32  	%r293, %r1094, %r292;
	or.b32  	%r55, %r293, %r271;
	or.b32  	%r294, %r270, 2080;
	xor.b32  	%r295, %r294, %r271;
	or.b32  	%r56, %r295, %r1094;
	or.b32  	%r296, %r270, 2592;
	xor.b32  	%r297, %r296, %r271;
	or.b32  	%r57, %r297, %r1094;
	or.b32  	%r298, %r268, 2096;
	xor.b32  	%r299, %r284, %r298;
	or.b32  	%r58, %r299, %r1094;
	or.b32  	%r300, %r268, 2608;
	xor.b32  	%r301, %r284, %r300;
	or.b32  	%r59, %r301, %r1094;
	or.b32  	%r302, %r268, 4112;
	xor.b32  	%r303, %r302, %r269;
	or.b32  	%r304, %r1094, %r303;
	or.b32  	%r60, %r304, %r271;
	or.b32  	%r305, %r268, 4624;
	xor.b32  	%r306, %r305, %r269;
	or.b32  	%r307, %r1094, %r306;
	or.b32  	%r61, %r307, %r271;
	or.b32  	%r308, %r270, 4128;
	xor.b32  	%r309, %r308, %r271;
	or.b32  	%r62, %r309, %r1094;
	or.b32  	%r310, %r270, 4640;
	xor.b32  	%r311, %r310, %r271;
	or.b32  	%r63, %r311, %r1094;
	or.b32  	%r312, %r268, 4144;
	xor.b32  	%r313, %r284, %r312;
	or.b32  	%r64, %r313, %r1094;
	or.b32  	%r314, %r268, 4656;
	xor.b32  	%r315, %r284, %r314;
	or.b32  	%r65, %r315, %r1094;
	or.b32  	%r316, %r268, 6160;
	xor.b32  	%r317, %r316, %r269;
	or.b32  	%r318, %r1094, %r317;
	or.b32  	%r66, %r318, %r271;
	or.b32  	%r319, %r268, 6672;
	xor.b32  	%r320, %r319, %r269;
	or.b32  	%r321, %r1094, %r320;
	or.b32  	%r67, %r321, %r271;
	or.b32  	%r322, %r270, 6176;
	xor.b32  	%r323, %r322, %r271;
	or.b32  	%r68, %r323, %r1094;
	or.b32  	%r324, %r270, 6688;
	xor.b32  	%r325, %r324, %r271;
	or.b32  	%r69, %r325, %r1094;
	or.b32  	%r326, %r268, 6192;
	xor.b32  	%r327, %r284, %r326;
	or.b32  	%r70, %r327, %r1094;
	or.b32  	%r328, %r268, 6704;
	xor.b32  	%r329, %r284, %r328;
	or.b32  	%r71, %r329, %r1094;
	mov.f32 	%f642, 0f00000000;
	mov.b32 	%r1091, -1;
	mov.b32 	%r1090, 0;
	mov.f32 	%f643, %f642;
	mov.f32 	%f644, %f642;
	mov.f32 	%f645, %f642;
	mov.f32 	%f646, %f642;
	mov.f32 	%f647, %f642;
	mov.f32 	%f648, %f642;
	mov.f32 	%f649, %f642;
	mov.f32 	%f650, %f642;
	mov.f32 	%f651, %f642;
	mov.f32 	%f652, %f642;
	mov.f32 	%f653, %f642;
	mov.f32 	%f654, %f642;
	mov.f32 	%f655, %f642;
	mov.f32 	%f656, %f642;
	mov.f32 	%f657, %f642;
	mov.f32 	%f658, %f642;
	mov.f32 	%f659, %f642;
	mov.f32 	%f660, %f642;
	mov.f32 	%f661, %f642;
	mov.f32 	%f662, %f642;
	mov.f32 	%f663, %f642;
	mov.f32 	%f664, %f642;
	mov.f32 	%f665, %f642;
	mov.f32 	%f666, %f642;
	mov.f32 	%f667, %f642;
	mov.f32 	%f668, %f642;
	mov.f32 	%f669, %f642;
	mov.f32 	%f670, %f642;
	mov.f32 	%f671, %f642;
	mov.f32 	%f672, %f642;
	mov.f32 	%f673, %f642;
	mov.f32 	%f674, %f642;
	mov.f32 	%f675, %f642;
	mov.f32 	%f676, %f642;
	mov.f32 	%f677, %f642;
	mov.f32 	%f678, %f642;
	mov.f32 	%f679, %f642;
	mov.f32 	%f680, %f642;
	mov.f32 	%f681, %f642;
	mov.f32 	%f682, %f642;
	mov.f32 	%f683, %f642;
	mov.f32 	%f684, %f642;
	mov.f32 	%f685, %f642;
	mov.f32 	%f686, %f642;
	mov.f32 	%f687, %f642;
	mov.f32 	%f688, %f642;
	mov.f32 	%f689, %f642;
	mov.f32 	%f690, %f642;
	mov.f32 	%f691, %f642;
	mov.f32 	%f692, %f642;
	mov.f32 	%f693, %f642;
	mov.f32 	%f694, %f642;
	mov.f32 	%f695, %f642;
	mov.f32 	%f696, %f642;
	mov.f32 	%f697, %f642;
	mov.f32 	%f698, %f642;
	mov.f32 	%f699, %f642;
	mov.f32 	%f700, %f642;
	mov.f32 	%f701, %f642;
	mov.f32 	%f702, %f642;
	mov.f32 	%f703, %f642;
	mov.f32 	%f704, %f642;
	mov.f32 	%f705, %f642;
	mov.u32 	%r1093, %r1090;
$L__BB0_3:                              // =>This Inner Loop Header: Depth=1
	.loc	1 37 19                         // matmul-with-tma-v3.py:37:19
	setp.lt.s32 	%p73, %r1093, %r9;
	add.s32 	%r821, %r1091, 1;
	setp.gt.s32 	%p74, %r821, 1;
	selp.b32 	%r1091, 0, %r821, %p74;
	selp.u32 	%r822, 1, 0, %p74;
	xor.b32  	%r1090, %r1090, %r822;
	shl.b32 	%r823, %r1091, 3;
	add.s32 	%r330, %r174, %r823;
	bar.sync 	0;
	// begin inline asm
	{
	.reg .pred P1;
	waitLoop:
	mbarrier.try_wait.parity.shared.b64 P1, [%r330], %r1090;
	@!P1 bra.uni waitLoop;
	}

	// end inline asm
	.loc	1 39 24                         // matmul-with-tma-v3.py:39:24
	shl.b32 	%r826, %r1091, 12;
	add.s32 	%r828, %r181, %r826;
	add.s32 	%r829, %r828, %r13;
	ld.shared.u8 	%rs97, [%r829];
	ld.shared.u8 	%rs98, [%r829+64];
	ld.shared.u8 	%rs99, [%r829+144];
	ld.shared.u8 	%rs100, [%r829+208];
	ld.shared.u8 	%rs101, [%r829+1024];
	ld.shared.u8 	%rs102, [%r829+1088];
	ld.shared.u8 	%rs103, [%r829+1168];
	ld.shared.u8 	%rs104, [%r829+1232];
	ld.shared.u8 	%rs105, [%r829+2048];
	ld.shared.u8 	%rs106, [%r829+2112];
	ld.shared.u8 	%rs107, [%r829+2192];
	ld.shared.u8 	%rs108, [%r829+2256];
	ld.shared.u8 	%rs109, [%r829+3072];
	ld.shared.u8 	%rs110, [%r829+3136];
	ld.shared.u8 	%rs111, [%r829+3216];
	ld.shared.u8 	%rs112, [%r829+3280];
	ld.shared.u8 	%rs113, [%r829+16];
	ld.shared.u8 	%rs114, [%r829+80];
	ld.shared.u8 	%rs115, [%r829+128];
	ld.shared.u8 	%rs116, [%r829+192];
	ld.shared.u8 	%rs117, [%r829+1040];
	ld.shared.u8 	%rs118, [%r829+1104];
	ld.shared.u8 	%rs119, [%r829+1152];
	ld.shared.u8 	%rs120, [%r829+1216];
	ld.shared.u8 	%rs121, [%r829+2064];
	ld.shared.u8 	%rs122, [%r829+2128];
	ld.shared.u8 	%rs123, [%r829+2176];
	ld.shared.u8 	%rs124, [%r829+2240];
	ld.shared.u8 	%rs125, [%r829+3088];
	ld.shared.u8 	%rs126, [%r829+3152];
	ld.shared.u8 	%rs127, [%r829+3200];
	ld.shared.u8 	%rs128, [%r829+3264];
	add.s32 	%r830, %r828, %r14;
	ld.shared.u8 	%rs129, [%r830];
	add.s32 	%r831, %r828, %r15;
	ld.shared.u8 	%rs130, [%r831];
	add.s32 	%r832, %r828, %r16;
	ld.shared.u8 	%rs131, [%r832];
	add.s32 	%r833, %r828, %r17;
	ld.shared.u8 	%rs132, [%r833];
	add.s32 	%r834, %r828, %r18;
	ld.shared.u8 	%rs133, [%r834];
	add.s32 	%r835, %r828, %r19;
	ld.shared.u8 	%rs134, [%r835];
	add.s32 	%r836, %r828, %r20;
	ld.shared.u8 	%rs135, [%r836];
	add.s32 	%r837, %r828, %r21;
	ld.shared.u8 	%rs136, [%r837];
	add.s32 	%r838, %r828, %r22;
	ld.shared.u8 	%rs137, [%r838];
	add.s32 	%r839, %r828, %r23;
	ld.shared.u8 	%rs138, [%r839];
	add.s32 	%r840, %r828, %r24;
	ld.shared.u8 	%rs139, [%r840];
	add.s32 	%r841, %r828, %r25;
	ld.shared.u8 	%rs140, [%r841];
	add.s32 	%r842, %r828, %r26;
	ld.shared.u8 	%rs141, [%r842];
	add.s32 	%r843, %r828, %r27;
	ld.shared.u8 	%rs142, [%r843];
	add.s32 	%r844, %r828, %r28;
	ld.shared.u8 	%rs143, [%r844];
	add.s32 	%r845, %r828, %r29;
	ld.shared.u8 	%rs144, [%r845];
	add.s32 	%r846, %r828, %r30;
	ld.shared.u8 	%rs145, [%r846];
	add.s32 	%r847, %r828, %r31;
	ld.shared.u8 	%rs146, [%r847];
	add.s32 	%r848, %r828, %r32;
	ld.shared.u8 	%rs147, [%r848];
	add.s32 	%r849, %r828, %r33;
	ld.shared.u8 	%rs148, [%r849];
	add.s32 	%r850, %r828, %r34;
	ld.shared.u8 	%rs149, [%r850];
	add.s32 	%r851, %r828, %r35;
	ld.shared.u8 	%rs150, [%r851];
	add.s32 	%r852, %r828, %r36;
	ld.shared.u8 	%rs151, [%r852];
	add.s32 	%r853, %r828, %r37;
	ld.shared.u8 	%rs152, [%r853];
	add.s32 	%r854, %r828, %r38;
	ld.shared.u8 	%rs153, [%r854];
	add.s32 	%r855, %r828, %r39;
	ld.shared.u8 	%rs154, [%r855];
	add.s32 	%r856, %r828, %r40;
	ld.shared.u8 	%rs155, [%r856];
	add.s32 	%r857, %r828, %r41;
	ld.shared.u8 	%rs156, [%r857];
	add.s32 	%r858, %r828, %r42;
	ld.shared.u8 	%rs157, [%r858];
	add.s32 	%r859, %r828, %r43;
	ld.shared.u8 	%rs158, [%r859];
	add.s32 	%r860, %r828, %r44;
	ld.shared.u8 	%rs159, [%r860];
	add.s32 	%r861, %r828, %r45;
	ld.shared.u8 	%rs160, [%r861];
	.loc	1 38 24                         // matmul-with-tma-v3.py:38:24
	shl.b32 	%r862, %r1091, 13;
	add.s32 	%r863, %r177, %r862;
	add.s32 	%r864, %r863, %r47;
	ld.shared.u32 	%r865, [%r864];
	ld.shared.u32 	%r866, [%r864+512];
	add.s32 	%r867, %r863, %r48;
	ld.shared.u32 	%r868, [%r867];
	add.s32 	%r869, %r863, %r49;
	ld.shared.u32 	%r870, [%r869];
	add.s32 	%r871, %r863, %r50;
	ld.shared.u32 	%r872, [%r871];
	add.s32 	%r873, %r863, %r51;
	ld.shared.u32 	%r874, [%r873];
	add.s32 	%r875, %r863, %r52;
	ld.shared.u32 	%r876, [%r875];
	add.s32 	%r877, %r863, %r53;
	ld.shared.u32 	%r878, [%r877];
	ld.shared.u32 	%r879, [%r864+2048];
	ld.shared.u32 	%r880, [%r864+2560];
	add.s32 	%r881, %r863, %r54;
	ld.shared.u32 	%r882, [%r881];
	add.s32 	%r883, %r863, %r55;
	ld.shared.u32 	%r884, [%r883];
	add.s32 	%r885, %r863, %r56;
	ld.shared.u32 	%r886, [%r885];
	add.s32 	%r887, %r863, %r57;
	ld.shared.u32 	%r888, [%r887];
	add.s32 	%r889, %r863, %r58;
	ld.shared.u32 	%r890, [%r889];
	add.s32 	%r891, %r863, %r59;
	ld.shared.u32 	%r892, [%r891];
	ld.shared.u32 	%r893, [%r864+4096];
	ld.shared.u32 	%r894, [%r864+4608];
	add.s32 	%r895, %r863, %r60;
	ld.shared.u32 	%r896, [%r895];
	add.s32 	%r897, %r863, %r61;
	ld.shared.u32 	%r898, [%r897];
	add.s32 	%r899, %r863, %r62;
	ld.shared.u32 	%r900, [%r899];
	add.s32 	%r901, %r863, %r63;
	ld.shared.u32 	%r902, [%r901];
	add.s32 	%r903, %r863, %r64;
	ld.shared.u32 	%r904, [%r903];
	add.s32 	%r905, %r863, %r65;
	ld.shared.u32 	%r906, [%r905];
	ld.shared.u32 	%r907, [%r864+6144];
	ld.shared.u32 	%r908, [%r864+6656];
	add.s32 	%r909, %r863, %r66;
	ld.shared.u32 	%r910, [%r909];
	add.s32 	%r911, %r863, %r67;
	ld.shared.u32 	%r912, [%r911];
	add.s32 	%r913, %r863, %r68;
	ld.shared.u32 	%r914, [%r913];
	add.s32 	%r915, %r863, %r69;
	ld.shared.u32 	%r916, [%r915];
	add.s32 	%r917, %r863, %r70;
	ld.shared.u32 	%r918, [%r917];
	add.s32 	%r919, %r863, %r71;
	ld.shared.u32 	%r920, [%r919];
	.loc	1 40 32                         // matmul-with-tma-v3.py:40:32
	mov.b32 	{%rs1, %rs2}, %r865;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r428, %rs1;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r524, %rs2;

	// end inline asm
	mov.b32 	{%rs3, %rs4}, %r866;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r429, %rs3;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r525, %rs4;

	// end inline asm
	mov.b32 	{%rs5, %rs6}, %r868;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r430, %rs5;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r526, %rs6;

	// end inline asm
	mov.b32 	{%rs7, %rs8}, %r870;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r431, %rs7;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r527, %rs8;

	// end inline asm
	mov.b32 	{%rs9, %rs10}, %r872;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r620, %rs9;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r716, %rs10;

	// end inline asm
	mov.b32 	{%rs11, %rs12}, %r874;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r621, %rs11;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r717, %rs12;

	// end inline asm
	mov.b32 	{%rs13, %rs14}, %r876;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r622, %rs13;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r718, %rs14;

	// end inline asm
	mov.b32 	{%rs15, %rs16}, %r878;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r623, %rs15;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r719, %rs16;

	// end inline asm
	mov.b32 	{%rs17, %rs18}, %r879;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r452, %rs17;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r548, %rs18;

	// end inline asm
	mov.b32 	{%rs19, %rs20}, %r880;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r453, %rs19;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r549, %rs20;

	// end inline asm
	mov.b32 	{%rs21, %rs22}, %r882;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r454, %rs21;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r550, %rs22;

	// end inline asm
	mov.b32 	{%rs23, %rs24}, %r884;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r455, %rs23;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r551, %rs24;

	// end inline asm
	mov.b32 	{%rs25, %rs26}, %r886;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r644, %rs25;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r740, %rs26;

	// end inline asm
	mov.b32 	{%rs27, %rs28}, %r888;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r645, %rs27;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r741, %rs28;

	// end inline asm
	mov.b32 	{%rs29, %rs30}, %r890;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r646, %rs29;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r742, %rs30;

	// end inline asm
	mov.b32 	{%rs31, %rs32}, %r892;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r647, %rs31;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r743, %rs32;

	// end inline asm
	mov.b32 	{%rs33, %rs34}, %r893;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r476, %rs33;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r572, %rs34;

	// end inline asm
	mov.b32 	{%rs35, %rs36}, %r894;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r477, %rs35;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r573, %rs36;

	// end inline asm
	mov.b32 	{%rs37, %rs38}, %r896;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r478, %rs37;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r574, %rs38;

	// end inline asm
	mov.b32 	{%rs39, %rs40}, %r898;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r479, %rs39;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r575, %rs40;

	// end inline asm
	mov.b32 	{%rs41, %rs42}, %r900;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r668, %rs41;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r764, %rs42;

	// end inline asm
	mov.b32 	{%rs43, %rs44}, %r902;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r669, %rs43;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r765, %rs44;

	// end inline asm
	mov.b32 	{%rs45, %rs46}, %r904;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r670, %rs45;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r766, %rs46;

	// end inline asm
	mov.b32 	{%rs47, %rs48}, %r906;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r671, %rs47;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r767, %rs48;

	// end inline asm
	mov.b32 	{%rs49, %rs50}, %r907;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r500, %rs49;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r596, %rs50;

	// end inline asm
	mov.b32 	{%rs51, %rs52}, %r908;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r501, %rs51;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r597, %rs52;

	// end inline asm
	mov.b32 	{%rs53, %rs54}, %r910;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r502, %rs53;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r598, %rs54;

	// end inline asm
	mov.b32 	{%rs55, %rs56}, %r912;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r503, %rs55;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r599, %rs56;

	// end inline asm
	mov.b32 	{%rs57, %rs58}, %r914;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r692, %rs57;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r788, %rs58;

	// end inline asm
	mov.b32 	{%rs59, %rs60}, %r916;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r693, %rs59;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r789, %rs60;

	// end inline asm
	mov.b32 	{%rs61, %rs62}, %r918;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r694, %rs61;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r790, %rs62;

	// end inline asm
	mov.b32 	{%rs63, %rs64}, %r920;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r695, %rs63;

	// end inline asm
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r791, %rs64;

	// end inline asm
	shl.b16 	%rs161, %rs98, 8;
	or.b16  	%rs65, %rs97, %rs161;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r432, %rs65;

	// end inline asm
	shl.b16 	%rs162, %rs100, 8;
	or.b16  	%rs66, %rs99, %rs162;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r528, %rs66;

	// end inline asm
	shl.b16 	%rs163, %rs102, 8;
	or.b16  	%rs67, %rs101, %rs163;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r433, %rs67;

	// end inline asm
	shl.b16 	%rs164, %rs104, 8;
	or.b16  	%rs68, %rs103, %rs164;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r529, %rs68;

	// end inline asm
	shl.b16 	%rs165, %rs106, 8;
	or.b16  	%rs69, %rs105, %rs165;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r624, %rs69;

	// end inline asm
	shl.b16 	%rs166, %rs108, 8;
	or.b16  	%rs70, %rs107, %rs166;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r720, %rs70;

	// end inline asm
	shl.b16 	%rs167, %rs110, 8;
	or.b16  	%rs71, %rs109, %rs167;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r625, %rs71;

	// end inline asm
	shl.b16 	%rs168, %rs112, 8;
	or.b16  	%rs72, %rs111, %rs168;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r721, %rs72;

	// end inline asm
	shl.b16 	%rs169, %rs114, 8;
	or.b16  	%rs73, %rs113, %rs169;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r438, %rs73;

	// end inline asm
	shl.b16 	%rs170, %rs116, 8;
	or.b16  	%rs74, %rs115, %rs170;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r534, %rs74;

	// end inline asm
	shl.b16 	%rs171, %rs118, 8;
	or.b16  	%rs75, %rs117, %rs171;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r439, %rs75;

	// end inline asm
	shl.b16 	%rs172, %rs120, 8;
	or.b16  	%rs76, %rs119, %rs172;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r535, %rs76;

	// end inline asm
	shl.b16 	%rs173, %rs122, 8;
	or.b16  	%rs77, %rs121, %rs173;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r630, %rs77;

	// end inline asm
	shl.b16 	%rs174, %rs124, 8;
	or.b16  	%rs78, %rs123, %rs174;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r726, %rs78;

	// end inline asm
	shl.b16 	%rs175, %rs126, 8;
	or.b16  	%rs79, %rs125, %rs175;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r631, %rs79;

	// end inline asm
	shl.b16 	%rs176, %rs128, 8;
	or.b16  	%rs80, %rs127, %rs176;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r727, %rs80;

	// end inline asm
	shl.b16 	%rs177, %rs130, 8;
	or.b16  	%rs81, %rs129, %rs177;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r444, %rs81;

	// end inline asm
	shl.b16 	%rs178, %rs132, 8;
	or.b16  	%rs82, %rs131, %rs178;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r540, %rs82;

	// end inline asm
	shl.b16 	%rs179, %rs134, 8;
	or.b16  	%rs83, %rs133, %rs179;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r445, %rs83;

	// end inline asm
	shl.b16 	%rs180, %rs136, 8;
	or.b16  	%rs84, %rs135, %rs180;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r541, %rs84;

	// end inline asm
	shl.b16 	%rs181, %rs138, 8;
	or.b16  	%rs85, %rs137, %rs181;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r636, %rs85;

	// end inline asm
	shl.b16 	%rs182, %rs140, 8;
	or.b16  	%rs86, %rs139, %rs182;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r732, %rs86;

	// end inline asm
	shl.b16 	%rs183, %rs142, 8;
	or.b16  	%rs87, %rs141, %rs183;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r637, %rs87;

	// end inline asm
	shl.b16 	%rs184, %rs144, 8;
	or.b16  	%rs88, %rs143, %rs184;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r733, %rs88;

	// end inline asm
	shl.b16 	%rs185, %rs146, 8;
	or.b16  	%rs89, %rs145, %rs185;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r450, %rs89;

	// end inline asm
	shl.b16 	%rs186, %rs148, 8;
	or.b16  	%rs90, %rs147, %rs186;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r546, %rs90;

	// end inline asm
	shl.b16 	%rs187, %rs150, 8;
	or.b16  	%rs91, %rs149, %rs187;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r451, %rs91;

	// end inline asm
	shl.b16 	%rs188, %rs152, 8;
	or.b16  	%rs92, %rs151, %rs188;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r547, %rs92;

	// end inline asm
	shl.b16 	%rs189, %rs154, 8;
	or.b16  	%rs93, %rs153, %rs189;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r642, %rs93;

	// end inline asm
	shl.b16 	%rs190, %rs156, 8;
	or.b16  	%rs94, %rs155, %rs190;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r738, %rs94;

	// end inline asm
	shl.b16 	%rs191, %rs158, 8;
	or.b16  	%rs95, %rs157, %rs191;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r643, %rs95;

	// end inline asm
	shl.b16 	%rs192, %rs160, 8;
	or.b16  	%rs96, %rs159, %rs192;
	// begin inline asm
	cvt.rn.f16x2.e5m2x2 %r739, %rs96;

	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f642, %f643, %f644, %f645 }, { %r428, %r429, %r430, %r431 }, { %r432, %r433 }, { %f642, %f643, %f644, %f645 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f646, %f647, %f648, %f649 }, { %r428, %r429, %r430, %r431 }, { %r438, %r439 }, { %f646, %f647, %f648, %f649 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f650, %f651, %f652, %f653 }, { %r428, %r429, %r430, %r431 }, { %r444, %r445 }, { %f650, %f651, %f652, %f653 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f654, %f655, %f656, %f657 }, { %r428, %r429, %r430, %r431 }, { %r450, %r451 }, { %f654, %f655, %f656, %f657 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f658, %f659, %f660, %f661 }, { %r452, %r453, %r454, %r455 }, { %r432, %r433 }, { %f658, %f659, %f660, %f661 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f662, %f663, %f664, %f665 }, { %r452, %r453, %r454, %r455 }, { %r438, %r439 }, { %f662, %f663, %f664, %f665 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f666, %f667, %f668, %f669 }, { %r452, %r453, %r454, %r455 }, { %r444, %r445 }, { %f666, %f667, %f668, %f669 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f670, %f671, %f672, %f673 }, { %r452, %r453, %r454, %r455 }, { %r450, %r451 }, { %f670, %f671, %f672, %f673 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f674, %f675, %f676, %f677 }, { %r476, %r477, %r478, %r479 }, { %r432, %r433 }, { %f674, %f675, %f676, %f677 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f678, %f679, %f680, %f681 }, { %r476, %r477, %r478, %r479 }, { %r438, %r439 }, { %f678, %f679, %f680, %f681 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f682, %f683, %f684, %f685 }, { %r476, %r477, %r478, %r479 }, { %r444, %r445 }, { %f682, %f683, %f684, %f685 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f686, %f687, %f688, %f689 }, { %r476, %r477, %r478, %r479 }, { %r450, %r451 }, { %f686, %f687, %f688, %f689 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f690, %f691, %f692, %f693 }, { %r500, %r501, %r502, %r503 }, { %r432, %r433 }, { %f690, %f691, %f692, %f693 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f694, %f695, %f696, %f697 }, { %r500, %r501, %r502, %r503 }, { %r438, %r439 }, { %f694, %f695, %f696, %f697 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f698, %f699, %f700, %f701 }, { %r500, %r501, %r502, %r503 }, { %r444, %r445 }, { %f698, %f699, %f700, %f701 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f702, %f703, %f704, %f705 }, { %r500, %r501, %r502, %r503 }, { %r450, %r451 }, { %f702, %f703, %f704, %f705 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f642, %f643, %f644, %f645 }, { %r524, %r525, %r526, %r527 }, { %r528, %r529 }, { %f642, %f643, %f644, %f645 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f646, %f647, %f648, %f649 }, { %r524, %r525, %r526, %r527 }, { %r534, %r535 }, { %f646, %f647, %f648, %f649 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f650, %f651, %f652, %f653 }, { %r524, %r525, %r526, %r527 }, { %r540, %r541 }, { %f650, %f651, %f652, %f653 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f654, %f655, %f656, %f657 }, { %r524, %r525, %r526, %r527 }, { %r546, %r547 }, { %f654, %f655, %f656, %f657 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f658, %f659, %f660, %f661 }, { %r548, %r549, %r550, %r551 }, { %r528, %r529 }, { %f658, %f659, %f660, %f661 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f662, %f663, %f664, %f665 }, { %r548, %r549, %r550, %r551 }, { %r534, %r535 }, { %f662, %f663, %f664, %f665 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f666, %f667, %f668, %f669 }, { %r548, %r549, %r550, %r551 }, { %r540, %r541 }, { %f666, %f667, %f668, %f669 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f670, %f671, %f672, %f673 }, { %r548, %r549, %r550, %r551 }, { %r546, %r547 }, { %f670, %f671, %f672, %f673 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f674, %f675, %f676, %f677 }, { %r572, %r573, %r574, %r575 }, { %r528, %r529 }, { %f674, %f675, %f676, %f677 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f678, %f679, %f680, %f681 }, { %r572, %r573, %r574, %r575 }, { %r534, %r535 }, { %f678, %f679, %f680, %f681 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f682, %f683, %f684, %f685 }, { %r572, %r573, %r574, %r575 }, { %r540, %r541 }, { %f682, %f683, %f684, %f685 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f686, %f687, %f688, %f689 }, { %r572, %r573, %r574, %r575 }, { %r546, %r547 }, { %f686, %f687, %f688, %f689 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f690, %f691, %f692, %f693 }, { %r596, %r597, %r598, %r599 }, { %r528, %r529 }, { %f690, %f691, %f692, %f693 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f694, %f695, %f696, %f697 }, { %r596, %r597, %r598, %r599 }, { %r534, %r535 }, { %f694, %f695, %f696, %f697 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f698, %f699, %f700, %f701 }, { %r596, %r597, %r598, %r599 }, { %r540, %r541 }, { %f698, %f699, %f700, %f701 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f702, %f703, %f704, %f705 }, { %r596, %r597, %r598, %r599 }, { %r546, %r547 }, { %f702, %f703, %f704, %f705 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f642, %f643, %f644, %f645 }, { %r620, %r621, %r622, %r623 }, { %r624, %r625 }, { %f642, %f643, %f644, %f645 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f646, %f647, %f648, %f649 }, { %r620, %r621, %r622, %r623 }, { %r630, %r631 }, { %f646, %f647, %f648, %f649 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f650, %f651, %f652, %f653 }, { %r620, %r621, %r622, %r623 }, { %r636, %r637 }, { %f650, %f651, %f652, %f653 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f654, %f655, %f656, %f657 }, { %r620, %r621, %r622, %r623 }, { %r642, %r643 }, { %f654, %f655, %f656, %f657 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f658, %f659, %f660, %f661 }, { %r644, %r645, %r646, %r647 }, { %r624, %r625 }, { %f658, %f659, %f660, %f661 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f662, %f663, %f664, %f665 }, { %r644, %r645, %r646, %r647 }, { %r630, %r631 }, { %f662, %f663, %f664, %f665 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f666, %f667, %f668, %f669 }, { %r644, %r645, %r646, %r647 }, { %r636, %r637 }, { %f666, %f667, %f668, %f669 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f670, %f671, %f672, %f673 }, { %r644, %r645, %r646, %r647 }, { %r642, %r643 }, { %f670, %f671, %f672, %f673 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f674, %f675, %f676, %f677 }, { %r668, %r669, %r670, %r671 }, { %r624, %r625 }, { %f674, %f675, %f676, %f677 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f678, %f679, %f680, %f681 }, { %r668, %r669, %r670, %r671 }, { %r630, %r631 }, { %f678, %f679, %f680, %f681 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f682, %f683, %f684, %f685 }, { %r668, %r669, %r670, %r671 }, { %r636, %r637 }, { %f682, %f683, %f684, %f685 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f686, %f687, %f688, %f689 }, { %r668, %r669, %r670, %r671 }, { %r642, %r643 }, { %f686, %f687, %f688, %f689 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f690, %f691, %f692, %f693 }, { %r692, %r693, %r694, %r695 }, { %r624, %r625 }, { %f690, %f691, %f692, %f693 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f694, %f695, %f696, %f697 }, { %r692, %r693, %r694, %r695 }, { %r630, %r631 }, { %f694, %f695, %f696, %f697 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f698, %f699, %f700, %f701 }, { %r692, %r693, %r694, %r695 }, { %r636, %r637 }, { %f698, %f699, %f700, %f701 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f702, %f703, %f704, %f705 }, { %r692, %r693, %r694, %r695 }, { %r642, %r643 }, { %f702, %f703, %f704, %f705 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f642, %f643, %f644, %f645 }, { %r716, %r717, %r718, %r719 }, { %r720, %r721 }, { %f642, %f643, %f644, %f645 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f646, %f647, %f648, %f649 }, { %r716, %r717, %r718, %r719 }, { %r726, %r727 }, { %f646, %f647, %f648, %f649 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f650, %f651, %f652, %f653 }, { %r716, %r717, %r718, %r719 }, { %r732, %r733 }, { %f650, %f651, %f652, %f653 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f654, %f655, %f656, %f657 }, { %r716, %r717, %r718, %r719 }, { %r738, %r739 }, { %f654, %f655, %f656, %f657 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f658, %f659, %f660, %f661 }, { %r740, %r741, %r742, %r743 }, { %r720, %r721 }, { %f658, %f659, %f660, %f661 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f662, %f663, %f664, %f665 }, { %r740, %r741, %r742, %r743 }, { %r726, %r727 }, { %f662, %f663, %f664, %f665 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f666, %f667, %f668, %f669 }, { %r740, %r741, %r742, %r743 }, { %r732, %r733 }, { %f666, %f667, %f668, %f669 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f670, %f671, %f672, %f673 }, { %r740, %r741, %r742, %r743 }, { %r738, %r739 }, { %f670, %f671, %f672, %f673 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f674, %f675, %f676, %f677 }, { %r764, %r765, %r766, %r767 }, { %r720, %r721 }, { %f674, %f675, %f676, %f677 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f678, %f679, %f680, %f681 }, { %r764, %r765, %r766, %r767 }, { %r726, %r727 }, { %f678, %f679, %f680, %f681 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f682, %f683, %f684, %f685 }, { %r764, %r765, %r766, %r767 }, { %r732, %r733 }, { %f682, %f683, %f684, %f685 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f686, %f687, %f688, %f689 }, { %r764, %r765, %r766, %r767 }, { %r738, %r739 }, { %f686, %f687, %f688, %f689 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f690, %f691, %f692, %f693 }, { %r788, %r789, %r790, %r791 }, { %r720, %r721 }, { %f690, %f691, %f692, %f693 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f694, %f695, %f696, %f697 }, { %r788, %r789, %r790, %r791 }, { %r726, %r727 }, { %f694, %f695, %f696, %f697 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f698, %f699, %f700, %f701 }, { %r788, %r789, %r790, %r791 }, { %r732, %r733 }, { %f698, %f699, %f700, %f701 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f702, %f703, %f704, %f705 }, { %r788, %r789, %r790, %r791 }, { %r738, %r739 }, { %f702, %f703, %f704, %f705 };
	// end inline asm
	.loc	1 37 19                         // matmul-with-tma-v3.py:37:19
	add.s32 	%r921, %r1092, 1;
	setp.lt.s32 	%p75, %r921, 2;
	selp.b32 	%r1092, %r921, 0, %p75;
	shl.b32 	%r922, %r1092, 3;
	add.s32 	%r812, %r174, %r922;
	bar.sync 	0;
	and.pred  	%p68, %p81, %p73;
	// begin inline asm
	@%p68 mbarrier.arrive.expect_tx.shared.b64 _, [%r812], 12288;
	// end inline asm
	.loc	1 38 24                         // matmul-with-tma-v3.py:38:24
	shl.b32 	%r923, %r1092, 13;
	add.s32 	%r813, %r177, %r923;
	bar.sync 	0;
	elect.sync 	%r924|%p76, -1;
	and.pred  	%p77, %p73, %p76;
	and.pred  	%p69, %p60, %p77;
	// begin inline asm
	@%p69 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r813], [%rd60, {%r1089, %r930}], [%r812];
	// end inline asm
	.loc	1 39 24                         // matmul-with-tma-v3.py:39:24
	shl.b32 	%r925, %r1092, 12;
	add.s32 	%r817, %r181, %r925;
	bar.sync 	0;
	elect.sync 	%r926|%p78, -1;
	and.pred  	%p79, %p73, %p78;
	and.pred  	%p70, %p60, %p79;
	// begin inline asm
	@%p70 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r817], [%rd61, {%r929, %r1089}], [%r812];
	// end inline asm
	.loc	1 37 19                         // matmul-with-tma-v3.py:37:19
	add.s32 	%r1093, %r1093, 1;
	add.s32 	%r1089, %r1089, 64;
	setp.ne.s32 	%p80, %r2, %r1093;
	@%p80 bra 	$L__BB0_3;
// %bb.4:                               // %._crit_edge.loopexit
	.loc	1 42 33                         // matmul-with-tma-v3.py:42:33
	cvt.rn.f16x2.f32 	%r1129, %f705, %f704;
	cvt.rn.f16x2.f32 	%r1128, %f703, %f702;
	cvt.rn.f16x2.f32 	%r1127, %f701, %f700;
	cvt.rn.f16x2.f32 	%r1126, %f699, %f698;
	cvt.rn.f16x2.f32 	%r1125, %f697, %f696;
	cvt.rn.f16x2.f32 	%r1124, %f695, %f694;
	cvt.rn.f16x2.f32 	%r1123, %f693, %f692;
	cvt.rn.f16x2.f32 	%r1122, %f691, %f690;
	cvt.rn.f16x2.f32 	%r1121, %f689, %f688;
	cvt.rn.f16x2.f32 	%r1120, %f687, %f686;
	cvt.rn.f16x2.f32 	%r1119, %f685, %f684;
	cvt.rn.f16x2.f32 	%r1118, %f683, %f682;
	cvt.rn.f16x2.f32 	%r1117, %f681, %f680;
	cvt.rn.f16x2.f32 	%r1116, %f679, %f678;
	cvt.rn.f16x2.f32 	%r1115, %f677, %f676;
	cvt.rn.f16x2.f32 	%r1114, %f675, %f674;
	cvt.rn.f16x2.f32 	%r1113, %f673, %f672;
	cvt.rn.f16x2.f32 	%r1112, %f671, %f670;
	cvt.rn.f16x2.f32 	%r1111, %f669, %f668;
	cvt.rn.f16x2.f32 	%r1110, %f667, %f666;
	cvt.rn.f16x2.f32 	%r1109, %f665, %f664;
	cvt.rn.f16x2.f32 	%r1108, %f663, %f662;
	cvt.rn.f16x2.f32 	%r1107, %f661, %f660;
	cvt.rn.f16x2.f32 	%r1106, %f659, %f658;
	cvt.rn.f16x2.f32 	%r1105, %f657, %f656;
	cvt.rn.f16x2.f32 	%r1104, %f655, %f654;
	cvt.rn.f16x2.f32 	%r1103, %f653, %f652;
	cvt.rn.f16x2.f32 	%r1102, %f651, %f650;
	cvt.rn.f16x2.f32 	%r1101, %f649, %f648;
	cvt.rn.f16x2.f32 	%r1100, %f647, %f646;
	cvt.rn.f16x2.f32 	%r1099, %f645, %f644;
	cvt.rn.f16x2.f32 	%r1098, %f643, %f642;
	bra.uni 	$L__BB0_5;
$L__BB0_1:                              // %.._crit_edge_crit_edge
	.loc	1 43 63                         // matmul-with-tma-v3.py:43:63
	and.b32  	%r1097, %r1, 8;
	and.b32  	%r1096, %r1, 16;
	shr.u32 	%r245, %r1, 2;
	and.b32  	%r1095, %r245, 8;
	shl.b32 	%r246, %r1, 4;
	and.b32  	%r1094, %r246, 1024;
	mov.u32 	%r1099, %r1098;
	mov.u32 	%r1100, %r1098;
	mov.u32 	%r1101, %r1098;
	mov.u32 	%r1102, %r1098;
	mov.u32 	%r1103, %r1098;
	mov.u32 	%r1104, %r1098;
	mov.u32 	%r1105, %r1098;
	mov.u32 	%r1106, %r1098;
	mov.u32 	%r1107, %r1098;
	mov.u32 	%r1108, %r1098;
	mov.u32 	%r1109, %r1098;
	mov.u32 	%r1110, %r1098;
	mov.u32 	%r1111, %r1098;
	mov.u32 	%r1112, %r1098;
	mov.u32 	%r1113, %r1098;
	mov.u32 	%r1114, %r1098;
	mov.u32 	%r1115, %r1098;
	mov.u32 	%r1116, %r1098;
	mov.u32 	%r1117, %r1098;
	mov.u32 	%r1118, %r1098;
	mov.u32 	%r1119, %r1098;
	mov.u32 	%r1120, %r1098;
	mov.u32 	%r1121, %r1098;
	mov.u32 	%r1122, %r1098;
	mov.u32 	%r1123, %r1098;
	mov.u32 	%r1124, %r1098;
	mov.u32 	%r1125, %r1098;
	mov.u32 	%r1126, %r1098;
	mov.u32 	%r1127, %r1098;
	mov.u32 	%r1128, %r1098;
	mov.u32 	%r1129, %r1098;
$L__BB0_5:                              // %._crit_edge
	.loc	1 37 19                         // matmul-with-tma-v3.py:37:19
	cp.async.wait_group 0;
	bar.sync 	0;
	// begin inline asm
	@%p81 mbarrier.inval.shared::cta.b64 [%r174];
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p81 mbarrier.inval.shared::cta.b64 [%r175];
	// end inline asm
	.loc	1 43 63                         // matmul-with-tma-v3.py:43:63
	shl.b32 	%r932, %r1, 1;
	and.b32  	%r933, %r932, 6;
	bfe.s32 	%r934, %r1, 2, 1;
	and.b32  	%r935, %r934, 72;
	or.b32  	%r936, %r935, %r933;
	setp.eq.s32 	%p85, %r1097, 0;
	selp.b32 	%r937, 0, 144, %p85;
	or.b32  	%r938, %r936, %r937;
	setp.eq.s32 	%p86, %r1096, 0;
	selp.b32 	%r939, 0, 288, %p86;
	or.b32  	%r940, %r938, %r939;
	xor.b32  	%r941, %r940, %r1095;
	or.b32  	%r942, %r941, %r1094;
	shl.b32 	%r943, %r942, 1;
	add.s32 	%r944, %r177, %r943;
	st.shared.b32 	[%r944], %r1098;
	or.b32  	%r945, %r940, 512;
	or.b32  	%r946, %r1094, %r1095;
	xor.b32  	%r947, %r946, %r945;
	shl.b32 	%r948, %r947, 1;
	add.s32 	%r949, %r177, %r948;
	st.shared.b32 	[%r949], %r1099;
	or.b32  	%r950, %r936, 16;
	xor.b32  	%r951, %r950, %r937;
	or.b32  	%r952, %r951, %r939;
	xor.b32  	%r953, %r946, %r952;
	shl.b32 	%r954, %r953, 1;
	add.s32 	%r955, %r177, %r954;
	st.shared.b32 	[%r955], %r1100;
	or.b32  	%r956, %r936, 528;
	xor.b32  	%r957, %r956, %r937;
	or.b32  	%r958, %r957, %r939;
	xor.b32  	%r959, %r946, %r958;
	shl.b32 	%r960, %r959, 1;
	add.s32 	%r961, %r177, %r960;
	st.shared.b32 	[%r961], %r1101;
	or.b32  	%r962, %r938, 32;
	or.b32  	%r963, %r946, %r939;
	xor.b32  	%r964, %r963, %r962;
	shl.b32 	%r965, %r964, 1;
	add.s32 	%r966, %r177, %r965;
	st.shared.b32 	[%r966], %r1102;
	or.b32  	%r967, %r938, 544;
	xor.b32  	%r968, %r963, %r967;
	shl.b32 	%r969, %r968, 1;
	add.s32 	%r970, %r177, %r969;
	st.shared.b32 	[%r970], %r1103;
	or.b32  	%r971, %r936, 48;
	or.b32  	%r972, %r963, %r937;
	xor.b32  	%r973, %r972, %r971;
	shl.b32 	%r974, %r973, 1;
	add.s32 	%r975, %r177, %r974;
	st.shared.b32 	[%r975], %r1104;
	or.b32  	%r976, %r936, 560;
	xor.b32  	%r977, %r972, %r976;
	shl.b32 	%r978, %r977, 1;
	add.s32 	%r979, %r177, %r978;
	st.shared.b32 	[%r979], %r1105;
	or.b32  	%r980, %r940, 2048;
	xor.b32  	%r981, %r946, %r980;
	shl.b32 	%r982, %r981, 1;
	add.s32 	%r983, %r177, %r982;
	st.shared.b32 	[%r983], %r1106;
	or.b32  	%r984, %r940, 2560;
	xor.b32  	%r985, %r946, %r984;
	shl.b32 	%r986, %r985, 1;
	add.s32 	%r987, %r177, %r986;
	st.shared.b32 	[%r987], %r1107;
	or.b32  	%r988, %r936, 2064;
	xor.b32  	%r989, %r988, %r937;
	or.b32  	%r990, %r989, %r939;
	xor.b32  	%r991, %r946, %r990;
	shl.b32 	%r992, %r991, 1;
	add.s32 	%r993, %r177, %r992;
	st.shared.b32 	[%r993], %r1108;
	or.b32  	%r994, %r936, 2576;
	xor.b32  	%r995, %r994, %r937;
	or.b32  	%r996, %r995, %r939;
	xor.b32  	%r997, %r946, %r996;
	shl.b32 	%r998, %r997, 1;
	add.s32 	%r999, %r177, %r998;
	st.shared.b32 	[%r999], %r1109;
	or.b32  	%r1000, %r938, 2080;
	xor.b32  	%r1001, %r963, %r1000;
	shl.b32 	%r1002, %r1001, 1;
	add.s32 	%r1003, %r177, %r1002;
	st.shared.b32 	[%r1003], %r1110;
	or.b32  	%r1004, %r938, 2592;
	xor.b32  	%r1005, %r963, %r1004;
	shl.b32 	%r1006, %r1005, 1;
	add.s32 	%r1007, %r177, %r1006;
	st.shared.b32 	[%r1007], %r1111;
	or.b32  	%r1008, %r936, 2096;
	xor.b32  	%r1009, %r972, %r1008;
	shl.b32 	%r1010, %r1009, 1;
	add.s32 	%r1011, %r177, %r1010;
	st.shared.b32 	[%r1011], %r1112;
	or.b32  	%r1012, %r936, 2608;
	xor.b32  	%r1013, %r972, %r1012;
	shl.b32 	%r1014, %r1013, 1;
	add.s32 	%r1015, %r177, %r1014;
	st.shared.b32 	[%r1015], %r1113;
	or.b32  	%r1016, %r940, 4096;
	xor.b32  	%r1017, %r946, %r1016;
	shl.b32 	%r1018, %r1017, 1;
	add.s32 	%r1019, %r177, %r1018;
	st.shared.b32 	[%r1019], %r1114;
	or.b32  	%r1020, %r940, 4608;
	xor.b32  	%r1021, %r946, %r1020;
	shl.b32 	%r1022, %r1021, 1;
	add.s32 	%r1023, %r177, %r1022;
	st.shared.b32 	[%r1023], %r1115;
	or.b32  	%r1024, %r936, 4112;
	xor.b32  	%r1025, %r1024, %r937;
	or.b32  	%r1026, %r1025, %r939;
	xor.b32  	%r1027, %r946, %r1026;
	shl.b32 	%r1028, %r1027, 1;
	add.s32 	%r1029, %r177, %r1028;
	st.shared.b32 	[%r1029], %r1116;
	or.b32  	%r1030, %r936, 4624;
	xor.b32  	%r1031, %r1030, %r937;
	or.b32  	%r1032, %r1031, %r939;
	xor.b32  	%r1033, %r946, %r1032;
	shl.b32 	%r1034, %r1033, 1;
	add.s32 	%r1035, %r177, %r1034;
	st.shared.b32 	[%r1035], %r1117;
	or.b32  	%r1036, %r938, 4128;
	xor.b32  	%r1037, %r963, %r1036;
	shl.b32 	%r1038, %r1037, 1;
	add.s32 	%r1039, %r177, %r1038;
	st.shared.b32 	[%r1039], %r1118;
	or.b32  	%r1040, %r938, 4640;
	xor.b32  	%r1041, %r963, %r1040;
	shl.b32 	%r1042, %r1041, 1;
	add.s32 	%r1043, %r177, %r1042;
	st.shared.b32 	[%r1043], %r1119;
	or.b32  	%r1044, %r936, 4144;
	xor.b32  	%r1045, %r972, %r1044;
	shl.b32 	%r1046, %r1045, 1;
	add.s32 	%r1047, %r177, %r1046;
	st.shared.b32 	[%r1047], %r1120;
	or.b32  	%r1048, %r936, 4656;
	xor.b32  	%r1049, %r972, %r1048;
	shl.b32 	%r1050, %r1049, 1;
	add.s32 	%r1051, %r177, %r1050;
	st.shared.b32 	[%r1051], %r1121;
	or.b32  	%r1052, %r940, 6144;
	xor.b32  	%r1053, %r946, %r1052;
	shl.b32 	%r1054, %r1053, 1;
	add.s32 	%r1055, %r177, %r1054;
	st.shared.b32 	[%r1055], %r1122;
	or.b32  	%r1056, %r940, 6656;
	xor.b32  	%r1057, %r946, %r1056;
	shl.b32 	%r1058, %r1057, 1;
	add.s32 	%r1059, %r177, %r1058;
	st.shared.b32 	[%r1059], %r1123;
	or.b32  	%r1060, %r936, 6160;
	xor.b32  	%r1061, %r1060, %r937;
	or.b32  	%r1062, %r1061, %r939;
	xor.b32  	%r1063, %r946, %r1062;
	shl.b32 	%r1064, %r1063, 1;
	add.s32 	%r1065, %r177, %r1064;
	st.shared.b32 	[%r1065], %r1124;
	or.b32  	%r1066, %r936, 6672;
	xor.b32  	%r1067, %r1066, %r937;
	or.b32  	%r1068, %r1067, %r939;
	xor.b32  	%r1069, %r946, %r1068;
	shl.b32 	%r1070, %r1069, 1;
	add.s32 	%r1071, %r177, %r1070;
	st.shared.b32 	[%r1071], %r1125;
	or.b32  	%r1072, %r938, 6176;
	xor.b32  	%r1073, %r963, %r1072;
	shl.b32 	%r1074, %r1073, 1;
	add.s32 	%r1075, %r177, %r1074;
	st.shared.b32 	[%r1075], %r1126;
	or.b32  	%r1076, %r938, 6688;
	xor.b32  	%r1077, %r963, %r1076;
	shl.b32 	%r1078, %r1077, 1;
	add.s32 	%r1079, %r177, %r1078;
	st.shared.b32 	[%r1079], %r1127;
	or.b32  	%r1080, %r936, 6192;
	xor.b32  	%r1081, %r972, %r1080;
	shl.b32 	%r1082, %r1081, 1;
	add.s32 	%r1083, %r177, %r1082;
	st.shared.b32 	[%r1083], %r1128;
	or.b32  	%r1084, %r936, 6704;
	xor.b32  	%r1085, %r972, %r1084;
	shl.b32 	%r1086, %r1085, 1;
	add.s32 	%r1087, %r177, %r1086;
	st.shared.b32 	[%r1087], %r1129;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	elect.sync 	%r1088|%p87, -1;
	and.pred  	%p83, %p60, %p87;
	// begin inline asm
	@%p83 cp.async.bulk.tensor.2d.global.shared::cta.bulk_group [%rd68, {%r929, %r930}], [%r177];
	// end inline asm
	cp.async.bulk.commit_group;
	cp.async.bulk.wait_group.read 0;
	.loc	1 43 4                          // matmul-with-tma-v3.py:43:4
	ret;
$L__tmp3:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/home/ubuntu/triton-ml-runner/examples/cubin_runner/sm120/matmul-with-tma-v3.py"
	.file	2 "/home/ubuntu/anaconda3/envs/triton/lib/python3.12/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 186                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0xb3 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 45
.b8 119
.b8 105
.b8 116
.b8 104
.b8 45
.b8 116
.b8 109
.b8 97
.b8 45
.b8 118
.b8 51
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 117
.b8 98
.b8 117
.b8 110
.b8 116
.b8 117
.b8 47
.b8 84
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 45
.b8 77
.b8 76
.b8 45
.b8 82
.b8 117
.b8 110
.b8 110
.b8 101
.b8 114
.b8 47
.b8 101
.b8 120
.b8 97
.b8 109
.b8 112
.b8 108
.b8 101
.b8 115
.b8 47
.b8 99
.b8 117
.b8 98
.b8 105
.b8 110
.b8 95
.b8 114
.b8 117
.b8 110
.b8 110
.b8 101
.b8 114
.b8 47
.b8 115
.b8 109
.b8 49
.b8 50
.b8 48
.b8 0
.b8 2                                   // Abbrev [2] 0x69:0x26 DW_TAG_subprogram
.b8 109                                 // DW_AT_name
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 95
.b8 109
.b8 97
.b8 107
.b8 101
.b8 95
.b8 116
.b8 101
.b8 110
.b8 115
.b8 111
.b8 114
.b8 95
.b8 100
.b8 101
.b8 115
.b8 99
.b8 105
.b8 112
.b8 116
.b8 111
.b8 114
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x8f:0x2e DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 105                                // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0xa4:0x18 DW_TAG_inlined_subroutine
.b32 105                                // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp2                           // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 37                                  // DW_AT_call_line
.b8 30                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
